<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Blog on Richard Faltings</title><link>https://rfaltings.com/posts/</link><description>Recent content in Blog on Richard Faltings</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 12 Aug 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://rfaltings.com/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>Introduction to Reinforcement Learning for Economists</title><link>https://rfaltings.com/posts/rl_econ/</link><pubDate>Fri, 12 Aug 2022 00:00:00 +0000</pubDate><guid>https://rfaltings.com/posts/rl_econ/</guid><description>Run on Google Colab to test out the code!
The purpose of this post is to introduce some basic concepts from the reinforcement learning (RL) literature using the setting and notation that is familiar to economists studying infinite horizon dynamic decision problems. In particular, I make use of Rust (1987)'s bus engine replacement problem as a demonstrative example.
Note: the methods discussed here are mainly concerned with solving the dynamic problem, and not with estimation.</description></item></channel></rss>