<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blogs on Richard Faltings</title>
    <link>https://rfaltings.github.io/blog/</link>
    <description>Recent content in Blogs on Richard Faltings</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://rfaltings.github.io/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>https://rfaltings.github.io/blog/rl_econ/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://rfaltings.github.io/blog/rl_econ/</guid>
      <description>Introduction to Reinforcement Learning for Economists Run on Google Colab to test out the code!
The purpose of this post is to introduce some basic concepts from the reinforcement learning (RL) literature using the setting and notation that is familiar to economists studying infinite horizon dynamic decision problems. In particular, I make use of Rust (1987)&amp;rsquo;s bus engine replacement problem as a demonstrative example.
Note: the methods discussed here are mainly concerned with solving the dynamic problem, and not with estimation.</description>
    </item>
    
  </channel>
</rss>
